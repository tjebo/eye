---
title: eye
output: github_document
bibliography: eye.bib
link-citations: true
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE, message=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
library(eye)
```

See more with *eye*. 

## Purpose
*eye* is dedicated to facilitate ophthalmic research. Its core functions [`blink()`](#blink), [`eyes()`](#eyes), [`myop()`](#myop), and [`va()`](#va) help with very common tasks:

- Visual acuity conversion
- Count eyes and patients 
- Shape data for analysis of visual acuity and intraocular pressure 

*eye* contains a [real life data set](#amd-data) and some functions beyond ophtalmology, which could make your data analysis a tiny bit more convenient.

*eye* includes [`geom_trail()`](#geom_trail) for some nice trail graphs. 

## Features 
### Only eye
- blink: [Perceive your data in a blink of an eye](#blink)
- eyes: [Easy count of patients and eyes](#eyes)
- va: [Conversion of visual acuity notations](#va) - includes conversion chart
- myop: [Make your eye data long](#myop)
- **AMD data**: Anonymised [real life data from a large cohort](https://datadryad.org/stash/dataset/doi:10.5061/dryad.97r9289) of patients with treatment-naive neovascular age-related macular degeneration (AMD) who received intravitreal anti-VEGF therapy in Moorfields Eye Hospital, London, UK. </br>
**To reference this data, please kindly cite the corresponding publication**.[@fasler] 

### Beyond eyes
- reveal: [Get common summary statistics](#reveal)
- age: [Calculate age](#age)
- csv: [Conveniently save a data frame to csv](#csv)
- geom_trail: [A base plot type = "b" equivalent for ggplot2](#geom_trail)

## Install *eye*
Currently only on github. 
```{r, eval=FALSE}
## for the development version 
devtools::install_github("tjebo/eye")
```

## Examples
Required packages
```{r, message=FALSE}
library(tidyverse)
```

### Only eye - core *eye* functions 
#### blink
#### eyes
Count patient and eyes (**eyes** or **eyestr**)
```{r eyes}
eyes(amd)

## Or get the text for reports
eyestr(amd)

## This will format numbers <=12 to english words
eyestr(head(amd, 100))
```

#### va
- *eye* includes a [visual acuity conversion chart: `va_chart`](#va-conversion-chart) 
- This chart and VA conversion formulas are based on [@holladay], [@beck] and [@gregori]
- Categories **counting fingers** and **hand movements** are converted following [@bach]
- Categories **no light perception** and **light perception** are converted following the suggestions by Michael Bach

```{r va}
## will automatically detect VA class and convert to logMAR by default
## ETDRS letters
va(c(23, 56, 74, 58)) 

## ... or convert to snellen
va(c(23, 56, 74, 58), to = "snellen") 

## snellen, mixed with categories. Also dealing with those "plus/minus" entries
va(c("NLP", "NPL", "PL", "LP", "HM", "CF", "6/60", "20/200", "6/9", "20/40", "20/40+3", "20/50-2"))

## on the inbuilt data set:
head(va(amd$VA_ETDRS_Letters), 10)

## (and indeed, there are unplausible ETDRS values in this data set!)
```


#### myop
Make your data long ("myopic")
```{r myop, echo=FALSE}
set.seed(42)
iop_wide <- data.frame(id = letters[1:3], iop_r = sample(11:13), iop_l = sample(14:16))
```
```{r myop2}
## Simple data frame with one column for right eye and left eye.
iop_wide

myop(iop_wide)
```
Often enough, there are right eye / left eye columns for more than one variable, e.g., for both IOP and VA. `myop` helps you clean this mess and will detect IOP and VA columns automatically.
```{r, echo=FALSE}
messy_df <- data.frame(
  id = letters[1:3], 
  iop_r_preop = sample(11:13), 
  iop_r_postop = sample(11:13), 
  iop_l_preop = sample(11:13), 
  iop_l_postop = sample(11:13), 
  va_r_preop= sample(41:43), 
  va_l_preop= sample(41:43),
  va_r_postop = sample(41:43), 
  va_l_postop = sample(41:43))
```
```{r myop two vars}
messy_df

clean_df <- myop(messy_df)

clean_df
```

### Beyond the eye
#### reveal
Show common statistics
```{r stats, warning=FALSE, message=FALSE}
amd_unq <- amd[!duplicated(amd$Id),]

reveal(amd_unq[c("BaselineAge", "VA_ETDRS_Letters", "FollowupDays")])
```

#### age
 - Calculate age in years, as [periods or durations](https://lubridate.tidyverse.org/articles/lubridate.html#time-intervals)
 - If only the start date given, calculating the age today.
```{r age, warning=FALSE, message=FALSE}
age("1984-10-16")

dob <-  c("1984-10-16", "2000-01-01")
test_date <-  as.Date(dob) + c(15000, 20000)

age(dob, test_date)
```

#### csv
- A convenience wrapper around `write.csv`. Saves a .csv file with the name of the data frame, or with a different name. 
```{r csv, warning=FALSE, message=FALSE, eval = FALSE}
csv(amd)
```

### ggplot2 extensions
#### geom_trail
A base plot type = "b" equivalent for ggplot. Works also with text!
<details>
  <summary>Prepare AMD data for plot (click to unfold) </summary>
```{r trail, message=FALSE}
amd_aggr <-
  amd %>%
  group_by(
    age_cut10 = cut_width(BaselineAge, 10),
    days_cut90 = cut_width(FollowupDays, 90, labels = seq(0, 810, 90))
  ) %>%
  summarise(mean_va = mean(VA_ETDRS_Letters)) 
```
</details>

```{r geom_trail}
p <-
  ggplot(amd_aggr, aes(days_cut90, mean_va, color = age_cut10)) +
    theme_classic() +
    labs(x = "Follow up time [Days]", y = "Mean VA [ETDRS letters]", 
         color = "Age strata")
```
```
p + geom_trail(aes(group = age_cut10))

p + geom_trail(aes(group = age_cut10), size = 0) +
          geom_text(aes(label = round(mean_va, 0)), show.legend = FALSE)
```
```{r, echo=FALSE, out.width="45%"}
p + geom_trail(aes(group = age_cut10))

p + geom_trail(aes(group = age_cut10), size = 0) +
          geom_text(aes(label = round(mean_va, 0)), show.legend = FALSE)
```

## Important information
**I do not assume responsability for your data or analysis**. Please stay always wary when working with data. If you get results that do not make sense, the most likely problem is that your data may not be entered in a way which is suitable for this package. I tried to think of many possible ways to deal with messy data, but I am sure there will be far more creative ways out there to abuse data entries. 

**The cleaner your data, the smoother this package will work** (any package, really!) 

Variable (column) names - There are not many rules to follow:

* No spaces! 
* Use common codes for eyes ("r", "re", "od", "right"). 
* Use common codes for your patient identifier (e.g., "pat", "patient" or "ID", ideally both: "patientID" or "patID")
* Common codes for visual acuity ("VA", "BCVA", "Acuity", "ETDRS", "logmar", "snellen") and intraocular pressure ("IOP", "GAT", "NCT") 
* Separate eye / va/ iop strings with underscores ("iop_l", "VA_r")
* **Don't be too creative with your names!** 

Good names (`eye` will work nicely)
```{r}
## Id and Eye are common names, there are no spaces
## VA is separated from the rest with an underscore
names(amd) 

## right and left eyes have common codes
## information on the tested dimension is included ("iop")
## iop and eye strings are separated by underscore
names(iop_wide) 
```

OK names (`eye` will work)
```{r}
## I recommend shorter names (for your own sake! 
## Coding becomes much easier)
c("id", "right_acuity",  "left_logmar") 

## All names are commonly used (good!)
## But which dimension of "r"/"l" are we exactly looking at? 
c("id", "r",  "l")
```

Bad names (`eye` will fail)
```{r}
## VA/IOP not separated with underscore
## `eye` won't be able to recognize IOP and VA columns
c("id", "iopr",  "iopl", "VAr", "VAl") 

## A human may think this is clear
## But `eye` will fail to understand those variable names
c("person", "goldmann", "vision") 

## Not even clear to humans 
c("var1", "var2",  "var3")
```


## Acknowledgements
- Thanks to Siegfried Wagner and Abraham Olvera, for their help with VA conversion
- Thanks to Tim Yap for helping find typos. All remaining typos are entirely his fault.
- Thanks to Hadley Wickham! Many of the functions in my package rely on the `tidyverse` package, but I would never have been able to make this package without his development tools `roxygen2`, `usethis`, `testthis` and `devtools`.

## VA conversion chart
<div style = "font-size:8 pt;">
|snellen_ft |snellen_m |snellen_dec |logMAR | ETDRS|quali |
|----------|---------|-----------|------|-----|-----|
|20/20000   |6/6000    |0.001       |3      |     0|NLP   |
|20/10000   |6/3000    |0.002       |2.7    |     0|LP    |
|20/4000    |6/1200    |0.005       |2.3    |     0|HM    |
|20/2000    |6/600     |0.01        |1.9    |     2|CF    |
|20/800     |6/240     |0.025       |1.6    |     5|NA    |
|20/630     |6/190     |0.032       |1.5    |    10|NA    |
|20/500     |6/150     |0.04        |1.4    |    15|NA    |
|20/400     |6/120     |0.05        |1.3    |    20|NA    |
|20/320     |6/96      |0.062       |1.2    |    25|NA    |
|20/300     |6/90      |0.067       |1.18   |    26|NA    |
|20/250     |6/75      |0.08        |1.1    |    30|NA    |
|20/200     |6/60      |0.1         |1.0    |    35|NA    |
|20/160     |6/48      |0.125       |0.9    |    40|NA    |
|20/125     |6/38      |0.16        |0.8    |    45|NA    |
|20/100     |6/30      |0.2         |0.7    |    50|NA    |
|20/80      |6/24      |0.25        |0.6    |    55|NA    |
|20/70      |6/21      |0.29        |0.54   |    58|NA    |
|20/63      |6/19      |0.32        |0.5    |    60|NA    |
|20/60      |6/18      |0.33        |0.48   |    61|NA    |
|20/50      |6/15      |0.4         |0.4    |    65|NA    |
|20/40      |6/12      |0.5         |0.3    |    70|NA    |
|20/32      |6/9.6     |0.625       |0.2    |    75|NA    |
|20/30      |6/9       |0.66        |0.18   |    76|NA    |
|20/25      |6/7.5     |0.8         |0.1    |    80|NA    |
|20/20      |6/6       |1.0         |0.0    |    85|NA    |
|20/16      |6/5       |1.25        |-0.1   |    90|NA    |
|20/15      |6/4.5     |1.33        |-0.12  |    91|NA    |
|20/13      |6/4       |1.5         |-0.2   |    95|NA    |
|20/10      |6/3       |2.0         |-0.3   |   100|NA    |
</div>

## Resources
[Michael Bach's homepage](https://michaelbach.de/sci/acuity.html)
[Michael Bach on NLP and LP](https://michaelbach.de/sci/pubs/Bach2007IOVS%20eLetter%20FrACT.pdf)

## References


